# Supported and current values of the ini file:
[global]
# The directory where the IO500 runs
datadir = /mnt/chqlustre1/scratch/scrusan/scratch/io500/dev
# The data directory is suffixed by a timestamp. Useful for running several IO500 tests concurrently.
#timestamp-datadir = FALSE
timestamp-datadir = TRUE
# The result directory.
resultdir = /mnt/shapurefb04_scratcht/systems/iobenchmarking/io500/results/chqlustre1-dev/submit
# The result directory is suffixed by a timestamp. Useful for running several IO500 tests concurrently.
timestamp-resultdir = TRUE
# The general API for the tests (to create/delete the datadir, extra options will be passed to IOR/mdtest)
#API = POSIX
api = POSIX --posix.odirect
# Purge the caches, this is useful for testing and needed for single node runs
drop-caches = FALSE
# Cache purging command, invoked before each I/O phase
drop-caches-cmd = sudo -n bash -c "echo 3 > /proc/sys/vm/drop_caches"
# Allocate the I/O buffers on the GPU
io-buffers-on-gpu = FALSE
# The verbosity level between 1 and 10
verbosity = 1
# Use the rules for the Student Cluster Competition
scc = FALSE
# Type of packet that will be created [timestamp|offset|incompressible|random]
dataPacketType = timestamp

[debug]
# For a valid result, the stonewall timer must be set to the value according to the rules. If smaller INVALIDATES RUN; FOR DEBUGGING.
stonewall-time = 300
# Pause between phases while in this directory lies a file with the phase name, e.g., easy-create. This can be useful for performance testing, e.g., of tiered storage. At the moment it INVALIDATES RUN; FOR DEBUGGING.
pause-dir = 

[ior-easy]
# The API to be used
# Transfer size
transferSize = 16m
#transferSize = 1m
# Block size; must be a multiple of transferSize
#blockSize = 9920000m
#blockSize = 99200m
blockSize = 128g
#blockSize = 2g
# Create one file per process
filePerProc = TRUE
# Use unique directory per file per process
uniqueDir = FALSE
# Run this phase
run = TRUE
# The verbosity level
verbosity = 
#api = POSIX --posix.odirect

[ior-easy-write]
# The API to be used
# Run this phase
run = TRUE

[mdtest-easy]
# The API to be used
# Files per proc
#n = 1000
#n = 150000
#n = 22000
n = 220000
# Run this phase
run = TRUE

[mdtest-easy-write]
# The API to be used
API = 
# Run this phase
run = TRUE
api = POSIX

[timestamp]

[find-easy]
# Set to an external script to perform the find phase
external-script = 
# Startup arguments for external scripts, some MPI's may not support this!
external-mpi-args = 
# Extra arguments for the external scripts
external-extra-args = 
# Set the number of processes for pfind/the external script
nproc = 
# Run this phase
run = TRUE
# Pfind queue length
#pfind-queue-length = 10000
#pfind-queue-length = 50000
pfind-queue-length = 100000
# Pfind Steal from next
pfind-steal-next = FALSE
# Parallelize the readdir by using hashing. Your system must support this!
#pfind-parallelize-single-dir-access-using-hashing = FALSE
pfind-parallelize-single-dir-access-using-hashing = TRUE

[ior-hard]
# The API to be used
# Number of segments
#segmentCount = 10000000
#segmentCount = 100000
segmentCount = 128000
#segmentCount = 10000
# Collective operation (for supported backends)
collective = 
# Run this phase
run = TRUE
# The verbosity level
verbosity = 
#api = POSIX --posix.odirect
api = POSIX
#api = MPIIO

[ior-hard-write]
# The API to be used
API = 
# Collective operation (for supported backends)
collective = 
# Run this phase
run = TRUE

[mdtest-hard]
# The API to be used
API = 
# Files per proc
#n = 30000
n = 300000
# File limit per directory (MDTest -I flag) to overcome file system limitations INVALIDATES RUN; FOR DEBUGGING.
files-per-dir = 
# Run this phase
run = TRUE

[mdtest-hard-write]
# The API to be used
API = 
# Run this phase
run = TRUE

[find]
# Set to an external script to perform the find phase
external-script = 
# Startup arguments for external scripts, some MPI's may not support this!
external-mpi-args = 
# Extra arguments for the external scripts
external-extra-args = 
# Set the number of processes for pfind/the external script
nproc = 
# Run this phase
run = TRUE
# Pfind queue length
#pfind-queue-length = 10000
pfind-queue-length = 100000
# Pfind Steal from next
pfind-steal-next = FALSE
# Parallelize the readdir by using hashing. Your system must support this!
#pfind-parallelize-single-dir-access-using-hashing = FALSE
pfind-parallelize-single-dir-access-using-hashing = TRUE

[find-hard]
# Set to an external script to perform the find phase
external-script = 
# Startup arguments for external scripts, some MPI's may not support this!
external-mpi-args = 
# Extra arguments for the external scripts
external-extra-args = 
# Set the number of processes for pfind/the external script
nproc = 
# Run this phase
run = TRUE
# Pfind queue length
#pfind-queue-length = 10000
#pfind-queue-length = 50000
pfind-queue-length = 100000
# Pfind Steal from next
pfind-steal-next = FALSE
# Parallelize the readdir by using hashing. Your system must support this!
#pfind-parallelize-single-dir-access-using-hashing = FALSE
pfind-parallelize-single-dir-access-using-hashing = TRUE

[ior-easy-read]
# The API to be used
API = 
# Run this phase
run = TRUE

[mdtest-easy-stat]
# The API to be used
API = 
# Run this phase
run = TRUE

[ior-hard-read]
# The API to be used
API = 
# Collective operation (for supported backends)
collective = 
# Run this phase
run = TRUE

[mdtest-hard-stat]
# The API to be used
API = 
# Run this phase
run = TRUE

[mdtest-easy-delete]
# The API to be used
API = 
# Run this phase
run = TRUE

[mdtest-hard-read]
# The API to be used
API = 
# Run this phase
run = TRUE

[mdtest-hard-delete]
# The API to be used
API = 
# Run this phase
run = TRUE

[ior-rnd4K-easy-read]
# The API to be used
API = POSIX --posix.odirect
#API = AIO --posix.odirect
# Run this phase
run = TRUE
