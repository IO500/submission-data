# Supported and current values of the ini file:
[global]
# The directory where the IO500 runs
datadir = /lustre_ai400x/io500/datafiles
# The data directory is suffixed by a timestamp. Useful for running several IO500 tests concurrently.
timestamp-datadir = TRUE
# The result directory.
resultdir = /lustre_ai400x/io500/results
# The result directory is suffixed by a timestamp. Useful for running several IO500 tests concurrently.
timestamp-resultdir = TRUE
# The general API for the tests (to create/delete the datadir, extra options will be passed to IOR/mdtest)
api = POSIX
# Purge the caches, this is useful for testing and needed for single node runs
drop-caches = FALSE
# Cache purging command, invoked before each I/O phase
drop-caches-cmd = sudo -n bash -c "echo 3 > /proc/sys/vm/drop_caches"
# Allocate the I/O buffers on the GPU
io-buffers-on-gpu = FALSE
# The verbosity level between 1 and 10
verbosity = 1
# Use the rules for the Student Cluster Competition
scc = FALSE

[debug]
# For a valid result, the stonewall timer must be set to the value according to the rules, it can be smaller for testing
stonewall-time = 300

[ior-easy]
# -t 16m --posix.odirect -a POSIX
# The API to be used
#API = 
#API = aio --aio.max-pending=64
API = POSIX --posix.odirect 
# Transfer size
#transferSize = 2m
transferSize = 16m
#transferSize = 4m
# Block size; must be a multiple of transferSize
#blockSize = 9920000m
#blockSize = 2048000m
# 96000m is good for 10x96
#blockSize = 96000m
#blockSize = 224000m
blockSize = 448000m
# Create one file per process
filePerProc = TRUE
# Use unique directory per file per process
uniqueDir = FALSE
#uniqueDir = TRUE
# Run this phase
run = TRUE
#run = FALSE
# The verbosity level
verbosity = 

[ior-easy-write]
# The API to be used
API = 

[ior-rnd]
# The API to be used
API = 
# Size of a random block, change only if explicitly allowed
blockSize = 1073741824
# Run this phase
#run = TRUE
run = FALSE
# The verbosity level
verbosity = 
# Prefill the file with this blocksize in bytes, e.g., 2097152
randomPrefill = 0

[ior-rnd-write]
# The API to be used
API = 

[mdtest-easy]
# The API to be used
#API = 
API = POSIX --posix.odirect 
# Files per proc
#n = 1000000
#n = 150000
# 75000 is good for 10x96
#n = 75000
# 250000 is good for 10x32
#n = 250000
# 100000 is good for 10x64
#n = 100000
#n = 110000
#n = 40000
#n = 25000
#n = 27000
n = 20000
# Run this phase
run = TRUE
#run = FALSE

[mdtest-easy-write]
# The API to be used
#API = 
API = POSIX --posix.odirect 
# Run this phase
run = TRUE
#run = FALSE

[mdworkbench]
# The API to be used
API = 
# Waiting time of an IO operation relative to runtime (1.0 is 100%%)
waitingTime = 0.0
# Files to precreate per set (always 10 sets), this is normally dynamically determined
precreatePerSet = 
# Files to run per iteration and set (always 10 sets), this is normally dynamically determined
filesPerProc = 
# Run this phase
#run = TRUE
run = FALSE
# The verbosity level
verbosity = 

[mdworkbench-create]
# Run this phase
#run = TRUE
run = FALSE

[timestamp]

[find-easy]
# Set to an external script to perform the find phase
external-script = 
# Startup arguments for external scripts, some MPI's may not support this!
external-mpi-args = 
# Extra arguments for the external scripts
external-extra-args = 
# Set the number of processes for pfind/the external script
nproc = 
# Run this phase
run = TRUE
#run = FALSE
# Pfind queue length
#pfind-queue-length = 10000
pfind-queue-length = 225000
# Pfind Steal from next
pfind-steal-next = FALSE
# Parallelize the readdir by using hashing. Your system must support this!
pfind-parallelize-single-dir-access-using-hashing = FALSE

[ior-hard]
# The API to be used
#API = POSIX --posix.odirect 
API = POSIX
#API = MPIIO
# Number of segments
#segmentCount = 10000000
# 150000 is good for 10x64
#segmentCount = 150000
#segmentCount = 100000
# 60000 is good for 140x16 with no overstriping
#segmentCount = 60000
# 90000 is good for 140x16 with overstriping
#segmentCount = 90000
# 18000 is good for 140x32 with no overstriping
#segmentCount = 18000
# 55000 is good for 140x32 with no overstriping
#segmentCount = 55000
segmentCount = 50000
# 75000 is good for 10x96
#segmentCount = 75000
# 225000 is good for 10x32
#segmentCount = 225000
# Collective operation (for supported backends)
collective = 
# Run this phase
run = TRUE
#run = FALSE
# The verbosity level
verbosity = 

[ior-hard-write]
# The API to be used
#API = POSIX --posix.odirect 
API = POSIX
#API = MPIIO
# Collective operation (for supported backends)
collective = 

[mdtest-hard]
# The API to be used
API = POSIX
#API = POSIX --posix.odirect 
# Files per proc
#n = 1000000
#n = 40000
# 20000 is good for 10x64
#n = 20000
#n = 14000
# 13500 is good for 10x96 or 140x32
#n = 13500 
n = 11500 
# 30000 is good for 10x32
#n = 30000
# File limit per directory (MDTest -I flag) to overcome file system limitations 
files-per-dir = 
# Run this phase
run = TRUE
#run = FALSE

[mdtest-hard-write]
# The API to be used
#API = 
#API = POSIX --posix.odirect 
# Run this phase
run = TRUE
#run = FALSE

[find]
# Set to an external script to perform the find phase
external-script = 
# Startup arguments for external scripts, some MPI's may not support this!
external-mpi-args = 
# Extra arguments for the external scripts
external-extra-args = 
# Set the number of processes for pfind/the external script
nproc = 
# Run this phase
run = TRUE
#run = FALSE
# Pfind queue length
pfind-queue-length = 225000
# Pfind Steal from next
pfind-steal-next = FALSE
# Parallelize the readdir by using hashing. Your system must support this!
pfind-parallelize-single-dir-access-using-hashing = FALSE

[ior-rnd-read]
# The API to be used
API = 

[find-hard]
# Set to an external script to perform the find phase
external-script = 
# Startup arguments for external scripts, some MPI's may not support this!
external-mpi-args = 
# Extra arguments for the external scripts
external-extra-args = 
# Set the number of processes for pfind/the external script
nproc = 
# Run this phase
run = TRUE
#run = FALSE
# Pfind queue length
#pfind-queue-length = 10000
pfind-queue-length = 225000
# Pfind Steal from next
pfind-steal-next = FALSE
# Parallelize the readdir by using hashing. Your system must support this!
pfind-parallelize-single-dir-access-using-hashing = FALSE

[mdworkbench-bench]
# Run this phase
#run = TRUE
run = FALSE

[ior-easy-read]
# The API to be used
API = 

[mdtest-easy-stat]
# The API to be used
#API = 
API = POSIX --posix.odirect 
# Run this phase
run = TRUE
#run = FALSE

[ior-hard-read]
# The API to be used
#API = POSIX --posix.odirect 
API = POSIX
#API = MPIIO
# Collective operation (for supported backends)
collective = 

[mdtest-hard-stat]
# The API to be used
#API = 
#API = POSIX --posix.odirect 
# Run this phase
run = TRUE
#run = FALSE

[mdworkbench-delete]
# Run this phase
#run = TRUE
run = FALSE

[mdtest-easy-delete]
# The API to be used
#API = 
API = POSIX --posix.odirect  
# Run this phase
run = TRUE
#run = FALSE

[mdtest-hard-read]
# The API to be used
#API = 
#API = POSIX --posix.odirect 
# Run this phase
run = TRUE
#run = FALSE

[mdtest-hard-delete]
# The API to be used
#API = 
#API = POSIX --posix.odirect 
# Run this phase
run = TRUE
#run = FALSE

